# Interpretability of deep learning for microscopic parasite image analysis

Deep learning, which played an increasingly important role in the recent years, has been also widely used to analyze microscopic images of parasites. However, deep learning lacks theoretical interpretability, which seriously hinders its application in parasite examination.<br> 


Our main contributions are as follows.<br>


### Multi-Parasite Dataset

To tackle the problem of lacking public parasitology datasets in deep learning, we publish a large-scale microscopic multi-parasite dataset, which can be downlaod [here](https://data.mendeley.com/datasets/4tnhbsh58c/draft?a=58f32edd-d920-49a2-b690-7eb8508400d9).<br>


Some Examples of our parasite dataset:

![](https://github.com/hello-code2021/IDLMPIA/blob/master/picture/dataset.png)


### CAM and Grad-CAM for Classification Interpretability of Deep Learning


As a good interpretability is required for biomedical clinical applications, we further interpret deep learning-based multi-parasite microscopic image classification by using Class Action Mapping(CAM) and Gradient-weighted Class Activation Mapping(Grad-CAM) visualization tools.<br>

![](https://github.com/hello-code2021/IDLMPIA/blob/master/picture/CAM_Grad-CAM.png)


Code for Classification, CAM, Grad-CAM and Confusion Matrix can be download above.



#### For other information, please contact the author zhangchi.ch@gmail.com and ee.jianghao@outlook.com.
